Discretize by Binning:Wartości atrybutów zmeniają postać z numerycznej na nominalną (przedziały liczbowe). Zmieniającparametr 'nuber of bins' wpływamy na ilość generowanych przedziałów. Przedziały są wyznaczane w taki sposób że ich zakres jest prawie równy.

Discretize by Entorpy: wartości atrybutów zmieniają jak wyżej postać z numerycznych na nominalną, z tym że granice przedziałów są wybierane tak aby zminimalizować entorpię (nieuporządkowanie) w poszczególnych przedziałach. Ponadto dyskretyzacja przez entropię odrzuca z automatu "bezużyteczne atrybuty", czyli takie, dla których został wyznaczony jeden przedział wartości. W rezultacie otrzymujemy zbiór z zredukowaną ilością atrybutów regularnych. W naszym przypadku zredukowano z 7171 do 11 atrybutów regularnych.

Detect outlier (LOF): dodaje każdemu rekordowi (przykładowi) kolumnę z wartością "local outlier factor", która wyznaczana jest na podstawie porównania lokalnej gęstości obiektu z lokalnymi gęstościami jego sąsiadów. W rezultacie  możemy zidentyfikować regiony o podobnej gęstości oraz punkty które mają znacznie niższą gęstość niż sąsiedzi (większy współczynnik) - wtedy obiekty te należy traktować jako przykłady odstające. Jako że korzystamy funkcji euklidesowego wysnaczania dystanów, dane uprzednio musimy znormalizować

Weights by correlation, select by weight: oblicza wagę dla każdego atrybutu wyznaczając wartość korelacji wejściowego zestawu przykładów w odniesieniu do atrybutu "label". Select by weight pozwala przefiltrować zbiór atrybutów, wybierając spośród nich te najważniejsze na podstawie wyznaczonych do nich wag.

decision tree: przed wykonaniem drzewa decyzyjnego, poddajemy dane dyskretyzacji przez entropię, aby odrzucić bezużyteczne atrybuty w celu przyśpiesznia wyznaczenia reguł decyzyjnych blokiem "Rule inducion". Po wykonaniu otrzymujemy wagi atrybuów, result test jak poprzednio oraz ukształtowane drzewo decyzyjne, które pokazuje nam na podstawie jakich wartości wybranych atrybutów możemy uważać że piosenka jest autorstwa danego zespołu.